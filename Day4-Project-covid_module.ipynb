{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2410099082.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[35], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    Find the original Notebook with detailed instructions by **Daniel Pass** [here](https://github.com/passdan/PracticalPythonProgrammingForBiologists/blob/main/Day4/P34B-Day4-Project-covid_modules.ipynb).\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Day3 Project Challenge - COVID module\n",
    "\n",
    "Find the original Notebook with detailed instructions by **Daniel Pass** [here](https://github.com/passdan/PracticalPythonProgrammingForBiologists/blob/main/Day4/P34B-Day4-Project-covid_modules.ipynb).\n",
    "\n",
    "Find the input file [here](inputData/Day4-Project-nextclade.fasta) and [here](inputData/Day4-Project-nextclade_metadata.csv).\n",
    "\n",
    "> In this exercise we are going to look at a complex dataset (n=126) of covid S protein reference sequences and associated metadata and statistics, and we're going to use some 3rd party modules to perform some higher-level analysis.\n",
    "> \n",
    "> As we have seen today there are many (many!) ways to approach any dataset. First consider a question that you want to test from this data. If you are more interested in statistical testing then you can focus on the metadata and statistics with pandas/scipy. If you are more interested in sequence bioinformatics then you can work with the fasta data. However you'll likely need both to fully investigate.\n",
    ">\n",
    "> You have been provided with two files:\n",
    ">\n",
    "> * [<code>Day4-Project-nextclade_metadata.csv</code>](inputData/Day4-Project-nextclade_metadata.csv) - Data & Metadata of 126 reference covid19 strains and the Spike (S) protein modificiation data\n",
    "> * [<code>Day4-Project-nextclade.fasta</code>](inputData/Day4-Project-nextclade.fasta) - Reference fasta sequence file for the corresponding spike proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\nicol\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/Day4-Project-nextclade_metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nicol\\Documents\\GitHub\\python_courseByPhysalia\\Day4-Project-covid_module.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/GitHub/python_courseByPhysalia/Day4-Project-covid_module.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mBio\u001b[39;00m \u001b[39mimport\u001b[39;00m SeqIO, Seq, SeqRecord\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/GitHub/python_courseByPhysalia/Day4-Project-covid_module.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Read in and filter the metadata file to remove bad and missing data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/GitHub/python_courseByPhysalia/Day4-Project-covid_module.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m covid_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/content/Day4-Project-nextclade_metadata.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/GitHub/python_courseByPhysalia/Day4-Project-covid_module.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m covid_data_cleaned \u001b[39m=\u001b[39m covid_data\u001b[39m.\u001b[39mdropna()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/GitHub/python_courseByPhysalia/Day4-Project-covid_module.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Read in the fasta sequence file. Only include sequences that have passed your step one filter!\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Day4-Project-nextclade_metadata.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO, Seq, SeqRecord\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "# Read in and filter the metadata file to remove bad and missing data\n",
    "covid_data = pd.read_csv(\"inputData/Day4-Project-nextclade_metadata.csv\")\n",
    "\n",
    "covid_data_cleaned = covid_data.dropna()\n",
    "\n",
    "# Read in the fasta sequence file. Only include sequences that have passed your step one filter!\n",
    "covid_seqs = []\n",
    "\n",
    "for seq in SeqIO.parse(\"inputData/Day4-Project-nextclade.fasta\", \"fasta\"):\n",
    "\n",
    "    if seq.id in list(covid_data_cleaned[\"seqName\"]):\n",
    "        covid_seqs.append(seq)\n",
    "\n",
    "# A function to output the spike protein sequence and key statistics (GC%, length, etc)\n",
    "def GCcalculator(ID):\n",
    "    sequence = ID.seq\n",
    "\n",
    "    GCcount = (sequence.count(\"G\") + sequence.count(\"C\")) / len(sequence) * 100\n",
    "\n",
    "    return GCcount\n",
    "\n",
    "for fasta_entry in covid_seqs:\n",
    "  print(f\"The sequence {fasta_entry.id} is {len(fasta_entry.seq)} nucleotides long and has GC content of {round(GCcalculator(fasta_entry))}%.\")\n",
    "\n",
    "# Calculate the mean number of substitutions per WHO clade\n",
    "substs_per_clade = covid_data_cleaned.groupby(\"clade\")[\"totalSubstitutions\"].mean()\n",
    "\n",
    "print(substs_per_clade)\n",
    "\n",
    "# Calculate the number/size of gap regions (strings of Ns) - does this correspond with the quality assesment?\n",
    "Ncount_list = []\n",
    "qualityScore_list = []\n",
    "qualityStatus_list = []\n",
    "for fasta_entry in covid_seqs:\n",
    "  # index = covid_data_cleaned.loc[covid_data_cleaned[\"seqName\"] == fasta_entry.id, \"index\"]\n",
    "  # print(f\"{index=}\")\n",
    "  sequence = fasta_entry.seq\n",
    "  Ncount = sequence.count('N')\n",
    "  qualityScore = covid_data_cleaned.loc[covid_data_cleaned.seqName == fasta_entry.id, \"qc.overallScore\"].iloc[0]\n",
    "  qualityStatus = covid_data_cleaned.loc[covid_data_cleaned.seqName == fasta_entry.id, \"qc.overallStatus\"].iloc[0]\n",
    "\n",
    "  Ncount_list.append(Ncount)\n",
    "  qualityScore_list.append(qualityScore)\n",
    "  qualityStatus_list.append(qualityStatus)\n",
    "\n",
    "stat, pvalue = spearmanr(Ncount_list, qualityScore_list)\n",
    "\n",
    "print()\n",
    "print(\"Spearman Rank test between NUMBER OF Ns and QUALITY SCORE\")\n",
    "print(f\"R2 = {round(stat,3)} (p = {round(pvalue,5)})\")\n",
    "print()\n",
    "\n",
    "plt.scatter(Ncount_list, qualityScore_list)\n",
    "plt.xlabel(\"Number of Ns\")\n",
    "plt.ylabel(\"Overall quality score\")\n",
    "plt.show()\n",
    "\n",
    "# Test for if binding efficiency correlates with any other variables, and plot the correlation.\n",
    "def test_corr(series1, series2):\n",
    "  stat, pvalue = spearmanr(series1, series2)\n",
    "  arg_names = inspect.getfullargspec(test_corr).args\n",
    "\n",
    "  if pvalue <= 0.05:\n",
    "    test = \"significant\"\n",
    "    return test, stat, pvalue\n",
    "  else:\n",
    "    test = \"not significant\"\n",
    "    return test, stat, pvalue\n",
    "\n",
    "for column in covid_data_cleaned:\n",
    "  if column == \"bindingEfficiency\" or column == \"index\" or column.startswith(\"alignment\"):\n",
    "    #print(f\"{column=} is not a valid column\")\n",
    "    continue\n",
    "\n",
    "  column_list = list(covid_data_cleaned[column])\n",
    "\n",
    "  if not all(isinstance(x, (float, int)) for x in column_list):\n",
    "    continue\n",
    "\n",
    "  bindingEfficiency_list = list(covid_data_cleaned.bindingEfficiency)\n",
    "  test_results = test_corr(bindingEfficiency_list, column_list)\n",
    "  \n",
    "  print()\n",
    "  print(f\"Spearman Rank test between binding efficiency and {column} is {test_results[0].upper()}\")\n",
    "  print(f\"R2 = {round(test_results[1],3)} (p = {round(test_results[2],5)})\")\n",
    "  print()\n",
    "\n",
    "  m, b = np.polyfit(bindingEfficiency_list, column_list, 1)\n",
    "  yp = np.polyval([m, b], bindingEfficiency_list)\n",
    "\n",
    "  if not test_results[0].startswith(\"not\"):\n",
    "    plt.plot(bindingEfficiency_list, yp, \"red\")\n",
    "  plt.scatter(bindingEfficiency_list, column_list)\n",
    "  plt.xlabel(\"Binding efficiency\")\n",
    "  plt.ylabel(f\"{column.capitalize()}\")\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
